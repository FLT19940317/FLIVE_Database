{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before run the .ipynb file, please follow the link and download AVA image database first.\n",
    "#### Link to download AVA: http://academictorrents.com/details/71631f83b11d3d79d8f84efe0a7e12f0ac001460\n",
    "#### Note: Need a Bittorrent client to download all the files\n",
    "#### After finishing downloading, we have an folder called \"AVA_dataset\" which contains all the 7z files of images\n",
    "#### Unzip all the files to the folder \"AVA_dataset\"\n",
    "#### Move the AVA_dataset which contains all AVA images to the folder \"database\" contained in our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Start ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import glob\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import urllib\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from clint.textui import progress\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Must be using Python 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader(url,parameters, file_name):\n",
    "    session = requests.Session()\n",
    "    response = session.get(url,params=parameters, stream=True)\n",
    "    if parameters is not None:\n",
    "        token = None\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                token = value\n",
    "        if token:\n",
    "            params = {'id': '0B7sjGeF4f3FYQUVlZ3ZOai1ieEU', 'confirm': token}\n",
    "            response = session.get('https://docs.google.com/uc?export=download', params=params, stream=True)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        total_size = 0\n",
    "        if file_name != 'emotic.zip':\n",
    "            total_size = int(response.headers.get('content-length'))\n",
    "        else:\n",
    "            total_size = 3602935747\n",
    "        with tqdm(total = int(total_size/32768), position=0, leave=True) as pbar:\n",
    "            for chunk in response.iter_content(32768):\n",
    "                f.write(chunk)\n",
    "                pbar.update()\n",
    "            #pbar.clear()\n",
    "            ##pbar.update()\n",
    "            #pbar.display(msg=\"downloading - done\",pos=1)\n",
    "            pbar.close()\n",
    "    print(\"%s downloading - Done!\" %file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download VOC ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61025it [02:57, 343.27it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc.tar downloading - Done!\n"
     ]
    }
   ],
   "source": [
    "url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar'\n",
    "parameters = None\n",
    "file_name = 'voc.tar'\n",
    "downloader(url, parameters, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17126it [00:39, 436.87it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC - Done!\n"
     ]
    }
   ],
   "source": [
    "tar = tarfile.open('voc.tar')\n",
    "tar.extractall('database/voc_emotic_ava')\n",
    "files = \"database/voc_emotic_ava/VOCdevkit/VOC2012/JPEGImages/*\"\n",
    "with tqdm(total = int(len(glob.glob(files))), position=0, leave=True) as pbar:\n",
    "    for path in glob.glob(files):\n",
    "        name = path.split(\"/\")[-1]\n",
    "        newp1 = path.replace(name,\"\")+\"JPEGImages__\"+name\n",
    "        newp2 = path.replace(name, \"\")+\"VOC\"+name\n",
    "        os.rename(path, newp1)\n",
    "        shutil.copy(newp1, 'database/voc_emotic_ava/')\n",
    "        os.rename(newp1, newp2)\n",
    "        shutil.copy(newp2, 'database/voc_emotic_ava/')\n",
    "        os.remove(newp2)\n",
    "        pbar.update()\n",
    "    pbar.update()\n",
    "    pbar.close()\n",
    "shutil.rmtree('database/voc_emotic_ava/VOCdevkit')\n",
    "print(\"VOC - Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Emotic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109956it [00:33, 3248.94it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotic.zip downloading - Done!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://docs.google.com/uc?export=download'\n",
    "parameters = {'id': '0B7sjGeF4f3FYQUVlZ3ZOai1ieEU'}\n",
    "file_name = 'emotic.zip'\n",
    "downloader(url, parameters, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:17<01:08, 17.21s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:19<00:37, 12.65s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:21<00:09,  9.25s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:47<00:00,  9.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotic - Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zipfile.ZipFile('emotic.zip', 'r').extractall('database/voc_emotic_ava')\n",
    "folders = os.listdir(\"database/voc_emotic_ava/emotic/\")\n",
    "with tqdm(total = len(folders), position=1, leave=True) as pbar:\n",
    "    for folder in folders: \n",
    "        files = \"database/voc_emotic_ava/emotic/\"+folder + \"/images/*\"\n",
    "        for path in glob.glob(files):\n",
    "            name = path.split(\"/\")[-1]\n",
    "            newp = path.replace(name,\"\")+\"EMOTIC__\"+name\n",
    "            os.rename(path, newp)\n",
    "            shutil.copy(newp, 'database/voc_emotic_ava/')\n",
    "            os.remove(newp)\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "shutil.rmtree('database/voc_emotic_ava/emotic')\n",
    "shutil.rmtree('database/voc_emotic_ava/__MACOSX')\n",
    "print(\"Emotic - Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Blur Detection Dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3731it [00:18, 202.04it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blur.zip downloading - Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.cse.cuhk.edu.hk/~leojia/projects/dblurdetect/data/BlurDatasetImage.zip'\n",
    "parameters = None\n",
    "file_name = 'blur.zip'\n",
    "downloader(url, parameters, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue dataset - Done!\n"
     ]
    }
   ],
   "source": [
    "zipfile.ZipFile('blur.zip','r').extractall('database/blur_dataset')\n",
    "for path in glob.glob('database/blur_dataset/image/*'):\n",
    "    shutil.copy(path, 'database/blur_dataset/')\n",
    "    os.remove(path)\n",
    "shutil.rmtree('database/blur_dataset/image')\n",
    "print(\"Blue dataset - Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename and Move AVA Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('database/AVA_dataset') == True:\n",
    "    files = 'database/AVA_dataset/images/*'\n",
    "    for path in tqdm(glob.glob(files)):\n",
    "        name = path.split(\"/\")[-1]\n",
    "        newp = path.replace(name, \"\")+\"AVA__\"+name\n",
    "        os.rename(path, newp)\n",
    "        shutil.move(newp, 'database/voc_emotic_ava/')\n",
    "    shutil.rmtree('database/voc_emotic_ava/AVA_dataset')\n",
    "    print(\"AVA - Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Image Not Been Used ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ims = pd.read_csv('labels_image.csv')\n",
    "ims = df_ims['name']\n",
    "ims = ims.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir('database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning - Done!\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    files = 'database/'+folder+\"/*\"\n",
    "    for path in glob.glob(files):\n",
    "        name = path.replace(\"database/\",\"\")\n",
    "        if name not in ims:\n",
    "            os.remove(path)\n",
    "print(\"Cleaning - Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Patches from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.isdir('database/patches') == False:\n",
    "        os.mkdir('database/patches')\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % 'patch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_sampling(im_path, patch_index, x, y, width, height):\n",
    "    img=cv2.imread(im_path)\n",
    "    patch = img[x:x+width, y:y+height]\n",
    "    name = im_path.split('/')[-1]\n",
    "    p_path = 'database/patches/'+name+\"_\"+\"patch_\"+str(patch_index)+\".jpg\"\n",
    "    cv2.imwrite(p_path,patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor = pd.read_csv('all_patches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch sampling - Done!\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    if folder != 'patches':\n",
    "        im_paths = 'database/'+folder+\"/*\"\n",
    "        im_name = im_path.split('/')[-1]\n",
    "        patch_name = \"patches/\"+im_name\n",
    "        row = df_coor.loc[df_coor['name_patch']==patch_name]\n",
    "        if len(row) == 1:\n",
    "            x1 = int(row['top_patch_1'].values.tolist()[0])\n",
    "            y1 = int(row['left_patch_1'].values.tolist()[0])\n",
    "            x2 = int(row['top_patch_2'].values.tolist()[0])\n",
    "            y2 = int(row['left_patch_2'].values.tolist()[0])\n",
    "            x3 = int(row['top_patch_3'].values.tolist()[0])\n",
    "            y3 = int(row['left_patch_3'].values.tolist()[0])\n",
    "            h1 = int(row['height_patch_1'].values.tolist()[0])\n",
    "            w1 = int(row['width_patch_1'].values.tolist()[0])\n",
    "            h2 = int(row['height_patch_2'].values.tolist()[0])\n",
    "            w2 = int(row['width_patch_2'].values.tolist()[0])\n",
    "            h3 = int(row['height_patch_3'].values.tolist()[0])\n",
    "            w3 = int(row['width_patch_3'].values.tolist()[0])\n",
    "            patch_sampling(im_path, 1, x1, y1, w1, h1)\n",
    "            patch_sampling(im_path, 2, x2, y2, w2, h2)\n",
    "            patch_sampling(im_path, 3, x3, y3, w3, h3)\n",
    "print(\"Patch sampling - Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
